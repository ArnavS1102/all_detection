{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":6200.0385,"end_time":"2023-07-22T23:28:13.821197","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-07-22T21:44:53.782697","version":"2.4.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ['CUDA_VISIBLE_DEVICES'] = '-1'","metadata":{"execution":{"iopub.execute_input":"2023-07-22T21:45:03.545228Z","iopub.status.busy":"2023-07-22T21:45:03.544820Z","iopub.status.idle":"2023-07-22T21:45:03.556586Z","shell.execute_reply":"2023-07-22T21:45:03.555754Z"},"papermill":{"duration":0.020632,"end_time":"2023-07-22T21:45:03.558735","exception":false,"start_time":"2023-07-22T21:45:03.538103","status":"completed"},"tags":[]},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"os.mkdir('vit')","metadata":{"execution":{"iopub.execute_input":"2023-07-22T21:45:03.568969Z","iopub.status.busy":"2023-07-22T21:45:03.568683Z","iopub.status.idle":"2023-07-22T21:45:03.573500Z","shell.execute_reply":"2023-07-22T21:45:03.572644Z"},"papermill":{"duration":0.012175,"end_time":"2023-07-22T21:45:03.575578","exception":false,"start_time":"2023-07-22T21:45:03.563403","status":"completed"},"tags":[]},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch\nuse_cuda = torch.cuda.is_available()","metadata":{"execution":{"iopub.execute_input":"2023-07-22T21:45:03.585656Z","iopub.status.busy":"2023-07-22T21:45:03.585405Z","iopub.status.idle":"2023-07-22T21:45:06.883066Z","shell.execute_reply":"2023-07-22T21:45:06.882095Z"},"papermill":{"duration":3.305559,"end_time":"2023-07-22T21:45:06.885663","exception":false,"start_time":"2023-07-22T21:45:03.580104","status":"completed"},"tags":[]},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"model_name = 'vit_go_orig-25e'","metadata":{"execution":{"iopub.execute_input":"2023-07-22T21:45:06.931172Z","iopub.status.busy":"2023-07-22T21:45:06.930914Z","iopub.status.idle":"2023-07-22T21:45:06.934828Z","shell.execute_reply":"2023-07-22T21:45:06.933897Z"},"id":"qSmhaxcRIPJg","papermill":{"duration":0.011328,"end_time":"2023-07-22T21:45:06.936795","exception":false,"start_time":"2023-07-22T21:45:06.925467","status":"completed"},"tags":[]},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import os\nimport json\nimport zipfile\nimport random\nimport shutil\nimport time\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\nimport tensorflow.keras as kr\n\nfrom matplotlib import pyplot as plt \nfrom PIL import Image\nfrom keras import backend as K\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.applications.resnet import preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard","metadata":{"execution":{"iopub.execute_input":"2023-07-22T21:45:06.947500Z","iopub.status.busy":"2023-07-22T21:45:06.946763Z","iopub.status.idle":"2023-07-22T21:45:15.730578Z","shell.execute_reply":"2023-07-22T21:45:15.729569Z"},"id":"weNs6Q7wIPJh","papermill":{"duration":8.791891,"end_time":"2023-07-22T21:45:15.733249","exception":false,"start_time":"2023-07-22T21:45:06.941358","status":"completed"},"tags":[]},"execution_count":7,"outputs":[{"name":"stderr","output_type":"stream","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"}]},{"cell_type":"code","source":"params = dict(\n    seed = 123,\n    image_dim = (168,168),\n    weight_decay = 1e-4,\n    epochs = 30,\n    batch_size = 4,\n    patch_size = 16,\n    pool_size = (2,2),\n    optimizer = 'Adam',\n    l_rate = 0.001,\n    val_split = .15,\n    use_transfer_learning = False,\n    use_data_aug = False,\n\n    l2_reg = .0,\n    projection_dim = 16,\n    num_heads = 3,\n    \n    transformer_layers = 4,\n    num_classes = 2,\n    mlp_head_units = [512,512]\n    \n    )\nnew_params = dict(\n    num_patches = (params['image_dim'][0] // params['patch_size']) ** 2,\n    transformer_units = [\n    params['projection_dim'] * 2,\n    params['projection_dim']],\n    input_shape = (params['image_dim'][0], params['image_dim'][1], 3),\n\n)\nparams.update(new_params)","metadata":{"execution":{"iopub.execute_input":"2023-07-22T21:45:15.746040Z","iopub.status.busy":"2023-07-22T21:45:15.744373Z","iopub.status.idle":"2023-07-22T21:45:15.753268Z","shell.execute_reply":"2023-07-22T21:45:15.752419Z"},"id":"uK94z_tOIPJi","papermill":{"duration":0.01702,"end_time":"2023-07-22T21:45:15.755412","exception":false,"start_time":"2023-07-22T21:45:15.738392","status":"completed"},"tags":[]},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nnp.random.seed(42)\ntf.random.set_seed(42)\n\ndef data_pipeline(batch_size, data_dir):\n    # Load and preprocess the image data\n    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n        data_dir,\n        labels=\"inferred\",\n        label_mode=\"categorical\",\n        class_names=[\"absent\", \"present\"],\n        batch_size=batch_size,\n        image_size=params[\"image_dim\"]\n    )\n\n    return dataset.shuffle(buffer_size=1000, seed=42)\n","metadata":{"execution":{"iopub.execute_input":"2023-07-22T21:45:15.785179Z","iopub.status.busy":"2023-07-22T21:45:15.783817Z","iopub.status.idle":"2023-07-22T21:45:15.790833Z","shell.execute_reply":"2023-07-22T21:45:15.789981Z"},"id":"6qHzfCE5IPJj","papermill":{"duration":0.014749,"end_time":"2023-07-22T21:45:15.792748","exception":false,"start_time":"2023-07-22T21:45:15.777999","status":"completed"},"tags":[]},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/c-nmc-whole'\n\ntrain_dir = os.path.join(data_dir, 'train')\ntest_dir = os.path.join(data_dir, 'test')\nval_dir = os.path.join(data_dir, 'validation')\n\ntrain_ds = data_pipeline(params[\"batch_size\"], train_dir)\nval_ds = data_pipeline(params[\"batch_size\"], val_dir)\ntest_ds = data_pipeline(params[\"batch_size\"], test_dir)","metadata":{"execution":{"iopub.execute_input":"2023-07-22T21:45:15.804433Z","iopub.status.busy":"2023-07-22T21:45:15.803019Z","iopub.status.idle":"2023-07-22T21:45:20.956602Z","shell.execute_reply":"2023-07-22T21:45:20.955659Z"},"id":"ZMPJkCsIIPJk","papermill":{"duration":5.161571,"end_time":"2023-07-22T21:45:20.959038","exception":false,"start_time":"2023-07-22T21:45:15.797467","status":"completed"},"tags":[]},"execution_count":11,"outputs":[{"name":"stdout","output_type":"stream","text":"Found 13583 files belonging to 2 classes.\n"},{"name":"stderr","output_type":"stream","text":"2023-07-22 21:45:20.371807: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"},{"name":"stdout","output_type":"stream","text":"Found 1746 files belonging to 2 classes.\n\nFound 1698 files belonging to 2 classes.\n"}]},{"cell_type":"code","source":"def mlp(x, hidden_units, dropout_rate):\n    for units in hidden_units:\n        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n        x = layers.Dropout(dropout_rate)(x)\n    return x\n\nclass Patches(layers.Layer):\n    def __init__(self, patch_size):\n        super(Patches, self).__init__()\n        self.patch_size = patch_size\n\n    def call(self, images):\n        batch_size = tf.shape(images)[0]\n        patches = tf.image.extract_patches(\n            images=images,\n            sizes=[1, self.patch_size, self.patch_size, 1],\n            strides=[1, self.patch_size, self.patch_size, 1],\n            rates=[1, 1, 1, 1],\n            padding=\"VALID\",\n        )\n        patch_dims = patches.shape[-1]\n        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n        return patches\n\n    \nclass PatchEncoder(layers.Layer):\n    def __init__(self, num_patches, projection_dim):\n        super(PatchEncoder, self).__init__()\n        self.num_patches = num_patches\n        self.projection = layers.Dense(units=projection_dim)\n        self.position_embedding = layers.Embedding(\n            input_dim=num_patches, output_dim=projection_dim\n        )\n\n    def call(self, patch):\n        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n        encoded = self.projection(patch) + self.position_embedding(positions)\n        return encoded","metadata":{"execution":{"iopub.execute_input":"2023-07-22T21:45:20.971533Z","iopub.status.busy":"2023-07-22T21:45:20.970616Z","iopub.status.idle":"2023-07-22T21:45:20.981439Z","shell.execute_reply":"2023-07-22T21:45:20.980595Z"},"id":"vKi3Omd3IPJk","papermill":{"duration":0.018989,"end_time":"2023-07-22T21:45:20.983378","exception":false,"start_time":"2023-07-22T21:45:20.964389","status":"completed"},"tags":[]},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def create_vit_classifier():\n    inputs = layers.Input(shape=params['input_shape'])\n    patches = Patches(params['patch_size'])(inputs)\n    encoded_patches = PatchEncoder(params['num_patches'], params['projection_dim'])(patches)\n\n    for _ in range(params['transformer_layers']):\n        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n        attention_output = layers.MultiHeadAttention(\n            num_heads=params['num_heads'], key_dim=params['projection_dim'], dropout=0.1\n        )(x1, x1)\n        x2 = layers.Add()([attention_output, encoded_patches])\n        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n        x3 = mlp(x3, hidden_units=params['transformer_units'], dropout_rate=0.1)\n        encoded_patches = layers.Add()([x3, x2])\n\n    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n    representation = tf.expand_dims(representation, axis=-1)\n    l2 = layers.MaxPool2D((2, 2), strides=2, padding='same')(representation)\n    l3 = layers.Conv2D(32, (3, 3), strides=1, padding='same', activation='relu')(l2)\n    l4 = layers.BatchNormalization()(l3)\n    l5 = layers.MaxPool2D((2, 2), strides=2, padding='same')(l4)\n    l6 = layers.Conv2D(64, (3, 3), strides=1, padding='same', activation='relu')(l5)\n    l7 = layers.Dropout(0.1)(l6)\n    l8 = layers.BatchNormalization()(l7)\n    l9 = layers.MaxPool2D((2, 2), strides=2, padding='same')(l8)\n    l13 = layers.Conv2D(128, (3, 3), strides=1, padding='same', activation='relu')(l9)\n    l14 = layers.Dropout(0.2)(l13)\n    l15 = layers.BatchNormalization()(l14)\n    l16 = layers.MaxPool2D((2, 2), strides=2, padding='same')(l15)\n    l17 = layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu')(l16)\n    l18 = layers.Dropout(0.2)(l17)\n    l19 = layers.BatchNormalization()(l18)\n    l20 = layers.MaxPool2D((2, 2), strides=2, padding='same')(l19)\n    l21 = layers.Conv2D(256, (3, 3), strides=1, padding='same', activation='relu')(l20)\n    l22 = layers.Dropout(0.2)(l21)\n    l23 = layers.BatchNormalization()(l22)\n    l24 = layers.MaxPool2D((2, 2), strides=2, padding='same')(l23)\n    representation = layers.Flatten()(l24)\n    representation = layers.Dropout(0.2)(representation)\n    features = mlp(representation, hidden_units=params['mlp_head_units'], dropout_rate=0.2)\n    logits = layers.Dense(2)(features)\n    model = keras.Model(inputs=inputs, outputs=logits)\n    return model\n","metadata":{"execution":{"iopub.execute_input":"2023-07-22T21:45:20.994641Z","iopub.status.busy":"2023-07-22T21:45:20.994367Z","iopub.status.idle":"2023-07-22T21:45:21.003570Z","shell.execute_reply":"2023-07-22T21:45:21.002639Z"},"id":"n6UxgScYIPJk","papermill":{"duration":0.017203,"end_time":"2023-07-22T21:45:21.005632","exception":false,"start_time":"2023-07-22T21:45:20.988429","status":"completed"},"tags":[]},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def run_experiment(model):\n    opt = keras.optimizers.Adam(learning_rate=params['l_rate'])\n    \n    def recall_m(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives / (possible_positives + K.epsilon())\n        return recall\n\n    def precision_m(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + K.epsilon())\n        return precision\n    \n    def f1_m(y_true, y_pred):\n        precision = precision_m(y_true, y_pred)\n        recall = recall_m(y_true, y_pred)\n        return 2*((precision*recall)/(precision+recall+K.epsilon()))\n\n    model.compile(\n        optimizer=opt,\n        loss=keras.losses.BinaryCrossentropy(from_logits=True),\n        metrics=[\n            keras.metrics.BinaryAccuracy(name=\"binary_accuracy\"), f1_m, recall_m, precision_m\n        ],\n    )\n\n\n    history = model.fit(\n        train_ds,\n        batch_size=params['batch_size'],\n        epochs=params['epochs'],\n        validation_data=val_ds\n    ) \n\n    return history, model\n\nmodel = create_vit_classifier()\nhistory, model = run_experiment(model)","metadata":{"execution":{"iopub.execute_input":"2023-07-22T21:45:21.016810Z","iopub.status.busy":"2023-07-22T21:45:21.016520Z","iopub.status.idle":"2023-07-22T23:27:49.788132Z","shell.execute_reply":"2023-07-22T23:27:49.787101Z"},"id":"qVLHsV13IPJl","papermill":{"duration":6148.780013,"end_time":"2023-07-22T23:27:49.790662","exception":false,"start_time":"2023-07-22T21:45:21.010649","status":"completed"},"tags":[]},"execution_count":14,"outputs":[{"name":"stdout","output_type":"stream","text":"Epoch 1/30\n\n3396/3396 [==============================] - 212s 58ms/step - loss: 0.7176 - binary_accuracy: 0.5290 - f1_m: 0.2007 - recall_m: 0.1625 - precision_m: 0.3079 - val_loss: 0.4890 - val_binary_accuracy: 0.7454 - val_f1_m: 0.7158 - val_recall_m: 0.6693 - val_precision_m: 0.7876\n\nEpoch 2/30\n\n3396/3396 [==============================] - 192s 56ms/step - loss: 0.5214 - binary_accuracy: 0.7155 - f1_m: 0.6647 - recall_m: 0.6077 - precision_m: 0.7700 - val_loss: 0.4287 - val_binary_accuracy: 0.7869 - val_f1_m: 0.7675 - val_recall_m: 0.7294 - val_precision_m: 0.8246\n\nEpoch 3/30\n\n3396/3396 [==============================] - 188s 55ms/step - loss: 0.4853 - binary_accuracy: 0.7519 - f1_m: 0.7226 - recall_m: 0.6777 - precision_m: 0.7953 - val_loss: 0.4156 - val_binary_accuracy: 0.7921 - val_f1_m: 0.7694 - val_recall_m: 0.7288 - val_precision_m: 0.8322\n\nEpoch 4/30\n\n3396/3396 [==============================] - 188s 55ms/step - loss: 0.4654 - binary_accuracy: 0.7651 - f1_m: 0.7387 - recall_m: 0.6955 - precision_m: 0.8076 - val_loss: 0.4009 - val_binary_accuracy: 0.8067 - val_f1_m: 0.7917 - val_recall_m: 0.7643 - val_precision_m: 0.8345\n\nEpoch 5/30\n\n3396/3396 [==============================] - 195s 56ms/step - loss: 0.4524 - binary_accuracy: 0.7728 - f1_m: 0.7474 - recall_m: 0.7058 - precision_m: 0.8130 - val_loss: 0.3979 - val_binary_accuracy: 0.8010 - val_f1_m: 0.7769 - val_recall_m: 0.7317 - val_precision_m: 0.8511\n\nEpoch 6/30\n\n3396/3396 [==============================] - 193s 56ms/step - loss: 0.4399 - binary_accuracy: 0.7848 - f1_m: 0.7644 - recall_m: 0.7274 - precision_m: 0.8233 - val_loss: 0.3926 - val_binary_accuracy: 0.8127 - val_f1_m: 0.8004 - val_recall_m: 0.7757 - val_precision_m: 0.8370\n\nEpoch 7/30\n\n3396/3396 [==============================] - 192s 56ms/step - loss: 0.4386 - binary_accuracy: 0.7879 - f1_m: 0.7685 - recall_m: 0.7330 - precision_m: 0.8242 - val_loss: 0.3990 - val_binary_accuracy: 0.8136 - val_f1_m: 0.8052 - val_recall_m: 0.7889 - val_precision_m: 0.8276\n\nEpoch 8/30\n\n3396/3396 [==============================] - 192s 56ms/step - loss: 0.4270 - binary_accuracy: 0.7922 - f1_m: 0.7742 - recall_m: 0.7410 - precision_m: 0.8246 - val_loss: 0.3962 - val_binary_accuracy: 0.8196 - val_f1_m: 0.8108 - val_recall_m: 0.7918 - val_precision_m: 0.8373\n\nEpoch 9/30\n\n3396/3396 [==============================] - 193s 56ms/step - loss: 0.4252 - binary_accuracy: 0.7925 - f1_m: 0.7732 - recall_m: 0.7363 - precision_m: 0.8306 - val_loss: 0.3915 - val_binary_accuracy: 0.8153 - val_f1_m: 0.8109 - val_recall_m: 0.8003 - val_precision_m: 0.8251\n\nEpoch 10/30\n\n3396/3396 [==============================] - 198s 57ms/step - loss: 0.4177 - binary_accuracy: 0.7988 - f1_m: 0.7792 - recall_m: 0.7432 - precision_m: 0.8352 - val_loss: 0.3828 - val_binary_accuracy: 0.8273 - val_f1_m: 0.8172 - val_recall_m: 0.7906 - val_precision_m: 0.8543\n\nEpoch 11/30\n\n3396/3396 [==============================] - 194s 56ms/step - loss: 0.4201 - binary_accuracy: 0.7967 - f1_m: 0.7785 - recall_m: 0.7439 - precision_m: 0.8313 - val_loss: 0.3725 - val_binary_accuracy: 0.8245 - val_f1_m: 0.8052 - val_recall_m: 0.7614 - val_precision_m: 0.8738\n\nEpoch 12/30\n\n3396/3396 [==============================] - 194s 56ms/step - loss: 0.4151 - binary_accuracy: 0.8017 - f1_m: 0.7838 - recall_m: 0.7476 - precision_m: 0.8389 - val_loss: 0.4061 - val_binary_accuracy: 0.8001 - val_f1_m: 0.7919 - val_recall_m: 0.7735 - val_precision_m: 0.8185\n\nEpoch 13/30\n\n3396/3396 [==============================] - 196s 57ms/step - loss: 0.4083 - binary_accuracy: 0.8079 - f1_m: 0.7921 - recall_m: 0.7597 - precision_m: 0.8407 - val_loss: 0.3727 - val_binary_accuracy: 0.8245 - val_f1_m: 0.8087 - val_recall_m: 0.7706 - val_precision_m: 0.8675\n\nEpoch 14/30\n\n3396/3396 [==============================] - 202s 58ms/step - loss: 0.4083 - binary_accuracy: 0.8041 - f1_m: 0.7855 - recall_m: 0.7501 - precision_m: 0.8395 - val_loss: 0.3700 - val_binary_accuracy: 0.8256 - val_f1_m: 0.8089 - val_recall_m: 0.7706 - val_precision_m: 0.8661\n\nEpoch 15/30\n\n3396/3396 [==============================] - 199s 58ms/step - loss: 0.4086 - binary_accuracy: 0.8076 - f1_m: 0.7909 - recall_m: 0.7569 - precision_m: 0.8437 - val_loss: 0.3695 - val_binary_accuracy: 0.8273 - val_f1_m: 0.8092 - val_recall_m: 0.7717 - val_precision_m: 0.8658\n\nEpoch 16/30\n\n3396/3396 [==============================] - 197s 57ms/step - loss: 0.4010 - binary_accuracy: 0.8109 - f1_m: 0.7938 - recall_m: 0.7595 - precision_m: 0.8467 - val_loss: 0.3699 - val_binary_accuracy: 0.8336 - val_f1_m: 0.8231 - val_recall_m: 0.7952 - val_precision_m: 0.8638\n\nEpoch 17/30\n\n3396/3396 [==============================] - 193s 56ms/step - loss: 0.3977 - binary_accuracy: 0.8115 - f1_m: 0.7943 - recall_m: 0.7585 - precision_m: 0.8489 - val_loss: 0.3694 - val_binary_accuracy: 0.8265 - val_f1_m: 0.8108 - val_recall_m: 0.7757 - val_precision_m: 0.8638\n\nEpoch 18/30\n\n3396/3396 [==============================] - 192s 56ms/step - loss: 0.3988 - binary_accuracy: 0.8120 - f1_m: 0.7953 - recall_m: 0.7608 - precision_m: 0.8477 - val_loss: 0.3712 - val_binary_accuracy: 0.8328 - val_f1_m: 0.8200 - val_recall_m: 0.7906 - val_precision_m: 0.8650\n\nEpoch 19/30\n\n3396/3396 [==============================] - 191s 55ms/step - loss: 0.3951 - binary_accuracy: 0.8134 - f1_m: 0.7961 - recall_m: 0.7607 - precision_m: 0.8503 - val_loss: 0.3670 - val_binary_accuracy: 0.8322 - val_f1_m: 0.8205 - val_recall_m: 0.7958 - val_precision_m: 0.8577\n\nEpoch 20/30\n\n3396/3396 [==============================] - 192s 56ms/step - loss: 0.3928 - binary_accuracy: 0.8150 - f1_m: 0.7988 - recall_m: 0.7637 - precision_m: 0.8524 - val_loss: 0.3733 - val_binary_accuracy: 0.8282 - val_f1_m: 0.8138 - val_recall_m: 0.7809 - val_precision_m: 0.8621\n\nEpoch 21/30\n\n3396/3396 [==============================] - 194s 56ms/step - loss: 0.3895 - binary_accuracy: 0.8171 - f1_m: 0.8025 - recall_m: 0.7703 - precision_m: 0.8508 - val_loss: 0.3677 - val_binary_accuracy: 0.8313 - val_f1_m: 0.8212 - val_recall_m: 0.7963 - val_precision_m: 0.8568\n\nEpoch 22/30\n\n3396/3396 [==============================] - 198s 57ms/step - loss: 0.3846 - binary_accuracy: 0.8170 - f1_m: 0.8008 - recall_m: 0.7668 - precision_m: 0.8526 - val_loss: 0.3638 - val_binary_accuracy: 0.8288 - val_f1_m: 0.8083 - val_recall_m: 0.7632 - val_precision_m: 0.8781\n\nEpoch 23/30\n\n3396/3396 [==============================] - 192s 56ms/step - loss: 0.3864 - binary_accuracy: 0.8162 - f1_m: 0.7989 - recall_m: 0.7619 - precision_m: 0.8545 - val_loss: 0.3641 - val_binary_accuracy: 0.8322 - val_f1_m: 0.8226 - val_recall_m: 0.7969 - val_precision_m: 0.8593\n\nEpoch 24/30\n\n3396/3396 [==============================] - 197s 57ms/step - loss: 0.3827 - binary_accuracy: 0.8201 - f1_m: 0.8044 - recall_m: 0.7706 - precision_m: 0.8561 - val_loss: 0.3783 - val_binary_accuracy: 0.8359 - val_f1_m: 0.8221 - val_recall_m: 0.7878 - val_precision_m: 0.8701\n\nEpoch 25/30\n\n3396/3396 [==============================] - 196s 57ms/step - loss: 0.3857 - binary_accuracy: 0.8181 - f1_m: 0.8007 - recall_m: 0.7655 - precision_m: 0.8545 - val_loss: 0.3779 - val_binary_accuracy: 0.8250 - val_f1_m: 0.8041 - val_recall_m: 0.7569 - val_precision_m: 0.8749\n\nEpoch 26/30\n\n3396/3396 [==============================] - 202s 59ms/step - loss: 0.3834 - binary_accuracy: 0.8209 - f1_m: 0.8044 - recall_m: 0.7691 - precision_m: 0.8581 - val_loss: 0.3801 - val_binary_accuracy: 0.8236 - val_f1_m: 0.8172 - val_recall_m: 0.8032 - val_precision_m: 0.8366\n\nEpoch 27/30\n\n3396/3396 [==============================] - 203s 59ms/step - loss: 0.3756 - binary_accuracy: 0.8246 - f1_m: 0.8088 - recall_m: 0.7740 - precision_m: 0.8611 - val_loss: 0.3641 - val_binary_accuracy: 0.8371 - val_f1_m: 0.8219 - val_recall_m: 0.7895 - val_precision_m: 0.8719\n\nEpoch 28/30\n\n3396/3396 [==============================] - 204s 59ms/step - loss: 0.3738 - binary_accuracy: 0.8233 - f1_m: 0.8070 - recall_m: 0.7717 - precision_m: 0.8605 - val_loss: 0.3728 - val_binary_accuracy: 0.8345 - val_f1_m: 0.8201 - val_recall_m: 0.7878 - val_precision_m: 0.8680\n\nEpoch 29/30\n\n3396/3396 [==============================] - 203s 59ms/step - loss: 0.3753 - binary_accuracy: 0.8223 - f1_m: 0.8054 - recall_m: 0.7708 - precision_m: 0.8589 - val_loss: 0.3717 - val_binary_accuracy: 0.8325 - val_f1_m: 0.8138 - val_recall_m: 0.7740 - val_precision_m: 0.8776\n\nEpoch 30/30\n\n3396/3396 [==============================] - 205s 59ms/step - loss: 0.3716 - binary_accuracy: 0.8255 - f1_m: 0.8091 - recall_m: 0.7741 - precision_m: 0.8624 - val_loss: 0.3699 - val_binary_accuracy: 0.8302 - val_f1_m: 0.8138 - val_recall_m: 0.7780 - val_precision_m: 0.8665\n"}]},{"cell_type":"code","source":"model.save('vit/model.h5')","metadata":{"execution":{"iopub.execute_input":"2023-07-22T23:28:03.581585Z","iopub.status.busy":"2023-07-22T23:28:03.581206Z","iopub.status.idle":"2023-07-22T23:28:03.757531Z","shell.execute_reply":"2023-07-22T23:28:03.756476Z"},"papermill":{"duration":7.201796,"end_time":"2023-07-22T23:28:03.760378","exception":false,"start_time":"2023-07-22T23:27:56.558582","status":"completed"},"tags":[]},"execution_count":15,"outputs":[]}]}